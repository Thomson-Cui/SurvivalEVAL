{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# For preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "import torch # For building the networks\n",
    "import torchtuples as tt # Some useful functions\n",
    "\n",
    "from pycox.datasets import metabric\n",
    "from pycox.models import LogisticHazard\n",
    "\n",
    "from Evaluations.One_Calibration import one_calibration_pycox\n",
    "from Evaluations.BrierScore import single_brier_score_pycox, integrated_brier_score_pycox\n",
    "from Evaluations.Concordance import concordance_pycox\n",
    "from Evaluations.L1 import l1_loss_pycox\n",
    "from Evaluations.D_Calibration import d_calibration_pycox\n",
    "\n",
    "from Evaluator import PycoxEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "_ = torch.manual_seed(123)\n",
    "\n",
    "df_train = metabric.read_df()\n",
    "df_test = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_test.index)\n",
    "df_val = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "cols_standardize = ['x0', 'x1', 'x2', 'x3', 'x8']\n",
    "cols_leave = ['x4', 'x5', 'x6', 'x7']\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "leave = [(col, None) for col in cols_leave]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardize + leave)\n",
    "\n",
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')\n",
    "\n",
    "\n",
    "num_durations = 10\n",
    "\n",
    "labtrans = LogisticHazard.label_transform(num_durations)\n",
    "# labtrans = PMF.label_transform(num_durations)\n",
    "# labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "\n",
    "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "# We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(df_test)\n",
    "durations_train, events_train = get_target(df_train)\n",
    "\n",
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "\n",
    "model = LogisticHazard(net, tt.optim.Adam(0.01), duration_index=labtrans.cuts)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "callbacks = [tt.cb.EarlyStopping()]\n",
    "\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, val_data=val)\n",
    "\n",
    "surv = model.interpolate(10).predict_surv_df(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval = PycoxEvaluator(surv, durations_test, events_test, durations_train, events_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cindex = eval.concordance()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bs = eval.brier_score()\n",
    "ibs2 = eval.integrated_brier_score()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_time = round(np.percentile(durations_test, 50))\n",
    "p_value1, ob1, pre1 = one_calibration_pycox(surv, durations_test, event_indicator=events_test, target_time=t_time, method=\"DN\")\n",
    "p_value2, ob2, pre2 = eval.one_calibration(target_time=t_time, method=\"DN\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l11 = l1_loss_pycox(surv, durations_test, events_test, durations_train, events_train, method='Margin', predicted_time_method=\"Mean\")\n",
    "l12 = eval.l1_loss(method='Margin', predicted_time_method=\"Mean\")\n",
    "print(\"l1 loss: {} and {}\".format(l11, l12))\n",
    "p_value1 = d_calibration_pycox(surv, durations_test, events_test)\n",
    "p_value2 = eval.d_calibration()\n",
    "print(\"D-cal: {} and {}\".format(p_value1, p_value2))\n",
    "\n",
    "# ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
    "# ev.concordance_td('antolini')\n",
    "# time_grid = np.linspace(durations_test.min(), durations_test.max(), 100)\n",
    "# ev.integrated_brier_score(time_grid)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}